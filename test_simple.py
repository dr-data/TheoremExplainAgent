#!/usr/bin/env python3
"""
Simple test to verify basic OpenRouter integration
"""

import os
import sys
sys.path.append(os.path.abspath('.'))

def test_basic_import():
    """Test that we can import and initialize the LiteLLMWrapper"""
    
    print("ğŸ§ª Basic OpenRouter Integration Test")
    print("=" * 40)
    
    try:
        from mllm_tools.litellm import LiteLLMWrapper
        print("âœ… Successfully imported LiteLLMWrapper")
        
        # Test initialization with OpenRouter model
        wrapper = LiteLLMWrapper(
            model_name="openrouter/openai/gpt-4o-mini",
            temperature=0.7,
            print_cost=False,
            verbose=False,
            use_langfuse=False
        )
        print("âœ… Successfully initialized LiteLLMWrapper with OpenRouter model")
        print(f"Model name: {wrapper.model_name}")
        print(f"Temperature: {wrapper.temperature}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def test_litellm_openrouter_support():
    """Test that litellm supports OpenRouter models"""
    
    print("\nğŸ” Testing LiteLLM OpenRouter Support")
    print("=" * 40)
    
    try:
        import litellm
        print("âœ… LiteLLM imported successfully")
        
        # Check if OpenRouter is in supported providers
        # Note: OpenRouter uses the OpenAI format, so it should work
        print("âœ… OpenRouter should work via OpenAI-compatible API")
        print("ğŸ“ Model format: openrouter/provider/model-name")
        print("ğŸ”— Base URL: https://openrouter.ai/api/v1")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error testing LiteLLM: {e}")
        return False

if __name__ == "__main__":
    success1 = test_basic_import()
    success2 = test_litellm_openrouter_support()
    
    print("\n" + "=" * 40)
    if success1 and success2:
        print("ğŸ‰ SUCCESS: Basic OpenRouter integration verified!")
        print("ğŸ“ The existing LiteLLMWrapper should work with OpenRouter models")
        print("ğŸ’¡ Just add OPENROUTER_API_KEY to your environment and use:")
        print("   --model 'openrouter/openai/gpt-4o-mini'")
    else:
        print("âš ï¸  Some issues detected")