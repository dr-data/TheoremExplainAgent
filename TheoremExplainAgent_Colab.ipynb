{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "theorem-explain-agent-header"
      },
      "source": [
        "# TheoremExplainAgent (TEA) üçµ - Google Colab Setup\n",
        "\n",
        "This notebook demonstrates how to set up and run TheoremExplainAgent in Google Colab with OpenRouter API support.\n",
        "\n",
        "## What is TheoremExplainAgent?\n",
        "\n",
        "TheoremExplainAgent is an AI-powered system that generates educational video content for mathematical theorems using:\n",
        "- **Manim Community**: Mathematical animations\n",
        "- **AI Models**: For content generation and planning\n",
        "- **Text-to-Speech**: For narration\n",
        "- **Multi-provider Support**: OpenAI, Anthropic, Google, OpenRouter, and more\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. **OpenRouter API Key** (recommended for cost-effective access): Get yours at [OpenRouter.ai](https://openrouter.ai/)\n",
        "2. Or any other supported LLM provider (OpenAI, Anthropic, Google, etc.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "installation-section"
      },
      "source": [
        "## 1. Installation and Setup\n",
        "\n",
        "### Install System Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-system-deps"
      },
      "outputs": [],
      "source": [
        "# Install system dependencies for Manim and audio processing\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq portaudio19-dev libsdl-pango-dev ffmpeg\n",
        "\n",
        "# Install LaTeX for mathematical typesetting\n",
        "!apt-get install -y -qq texlive texlive-latex-extra texlive-fonts-extra texlive-latex-recommended texlive-science tipa\n",
        "\n",
        "print(\"‚úÖ System dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clone-repo-section"
      },
      "source": [
        "### Clone Repository and Install Python Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone-and-install"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/dr-data/TheoremExplainAgent.git\n",
        "%cd TheoremExplainAgent\n",
        "\n",
        "# Install Python dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "print(\"‚úÖ Repository cloned and dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-models-section"
      },
      "source": [
        "### Download Required Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-models"
      },
      "outputs": [],
      "source": [
        "# Create models directory and download Kokoro TTS models\n",
        "!mkdir -p models\n",
        "!wget -P models https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files/kokoro-v0_19.onnx\n",
        "!wget -P models https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files/voices.bin\n",
        "\n",
        "print(\"‚úÖ Kokoro TTS models downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "environment-setup-section"
      },
      "source": [
        "## 2. Environment Configuration\n",
        "\n",
        "### Set up API Keys and Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-environment"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Set up OpenRouter API (recommended for cost-effective access)\n",
        "print(\"üîë Setting up OpenRouter API\")\n",
        "print(\"Get your API key from: https://openrouter.ai/\")\n",
        "openrouter_key = getpass(\"Enter your OpenRouter API key: \")\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = openrouter_key\n",
        "os.environ[\"OPENROUTER_API_BASE_URL\"] = \"https://openrouter.ai/api/v1\"\n",
        "\n",
        "# Kokoro TTS Settings\n",
        "os.environ[\"KOKORO_MODEL_PATH\"] = \"models/kokoro-v0_19.onnx\"\n",
        "os.environ[\"KOKORO_VOICES_PATH\"] = \"models/voices.bin\"\n",
        "os.environ[\"KOKORO_DEFAULT_VOICE\"] = \"af\"\n",
        "os.environ[\"KOKORO_DEFAULT_SPEED\"] = \"1.0\"\n",
        "os.environ[\"KOKORO_DEFAULT_LANG\"] = \"en-us\"\n",
        "\n",
        "# Set Python path for proper imports\n",
        "import sys\n",
        "sys.path.append('/content/TheoremExplainAgent')\n",
        "os.environ[\"PYTHONPATH\"] = \"/content/TheoremExplainAgent\"\n",
        "\n",
        "print(\"‚úÖ Environment configured successfully!\")\n",
        "print(\"üìù You can also use other providers like OpenAI, Anthropic, Google, etc.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alternative-providers-section"
      },
      "source": [
        "### Optional: Configure Alternative Providers\n",
        "\n",
        "If you prefer to use other LLM providers, uncomment and run the relevant section below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-alternative-providers"
      },
      "outputs": [],
      "source": [
        "# Uncomment the provider you want to use:\n",
        "\n",
        "# # OpenAI\n",
        "# openai_key = getpass(\"Enter your OpenAI API key: \")\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "# # Anthropic\n",
        "# anthropic_key = getpass(\"Enter your Anthropic API key: \")\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = anthropic_key\n",
        "\n",
        "# # Google Gemini\n",
        "# gemini_key = getpass(\"Enter your Google Gemini API key: \")\n",
        "# os.environ[\"GEMINI_API_KEY\"] = gemini_key\n",
        "\n",
        "# # Azure OpenAI\n",
        "# azure_key = getpass(\"Enter your Azure OpenAI API key: \")\n",
        "# azure_base = input(\"Enter your Azure OpenAI base URL: \")\n",
        "# azure_version = input(\"Enter your Azure OpenAI API version: \")\n",
        "# os.environ[\"AZURE_API_KEY\"] = azure_key\n",
        "# os.environ[\"AZURE_API_BASE\"] = azure_base\n",
        "# os.environ[\"AZURE_API_VERSION\"] = azure_version\n",
        "\n",
        "print(\"‚ÑπÔ∏è Alternative provider setup complete (if configured)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test-setup-section"
      },
      "source": [
        "## 3. Test the Setup\n",
        "\n",
        "### Verify Installation and API Connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test-installation"
      },
      "outputs": [],
      "source": [
        "# Test import of key modules\n",
        "try:\n",
        "    from mllm_tools.litellm import LiteLLMWrapper\n",
        "    from src.config.config import Config\n",
        "    import litellm\n",
        "    print(\"‚úÖ Core modules imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"üîß Try restarting the runtime and running all cells again\")\n",
        "\n",
        "# Test model connectivity with a simple completion\n",
        "try:\n",
        "    # Test with OpenRouter model (cost-effective)\n",
        "    test_model = LiteLLMWrapper(\n",
        "        model_name=\"openrouter/openai/gpt-4o-mini\",  # Cost-effective model\n",
        "        temperature=0.7,\n",
        "        print_cost=True,\n",
        "        verbose=True,\n",
        "        use_langfuse=False  # Disable for testing\n",
        "    )\n",
        "    \n",
        "    # Simple test message\n",
        "    test_messages = [\n",
        "        {\"type\": \"text\", \"content\": \"Hello! Can you briefly explain what a mathematical theorem is?\"}\n",
        "    ]\n",
        "    \n",
        "    response = test_model(test_messages)\n",
        "    print(\"\\n‚úÖ Model test successful!\")\n",
        "    print(f\"üìù Response preview: {response[:100]}...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Model test failed: {e}\")\n",
        "    print(\"üîß Check your API key and internet connection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generation-examples-section"
      },
      "source": [
        "## 4. Generate Educational Videos\n",
        "\n",
        "### Example 1: Single Topic Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate-single-topic"
      },
      "outputs": [],
      "source": [
        "# Generate a video for a single mathematical topic\n",
        "!python generate_video.py \\\n",
        "    --model \"openrouter/openai/gpt-4o-mini\" \\\n",
        "    --helper_model \"openrouter/openai/gpt-4o-mini\" \\\n",
        "    --output_dir \"output/pythagorean_theorem\" \\\n",
        "    --topic \"Pythagorean theorem\" \\\n",
        "    --context \"fundamental relation in Euclidean geometry among the three sides of a right triangle: a¬≤ + b¬≤ = c¬≤\" \\\n",
        "    --verbose\n",
        "\n",
        "print(\"\\n‚úÖ Single topic generation complete!\")\n",
        "print(\"üìÅ Check the output/pythagorean_theorem directory for results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch-generation-section"
      },
      "source": [
        "### Example 2: Batch Generation from Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate-batch"
      },
      "outputs": [],
      "source": [
        "# Generate videos for multiple theorems from the provided dataset\n",
        "!python generate_video.py \\\n",
        "    --model \"openrouter/anthropic/claude-3-haiku\" \\\n",
        "    --helper_model \"openrouter/anthropic/claude-3-haiku\" \\\n",
        "    --output_dir \"output/batch_experiment\" \\\n",
        "    --theorems_path \"data/easy_20.json\" \\\n",
        "    --sample_size 3 \\\n",
        "    --max_scene_concurrency 2 \\\n",
        "    --max_topic_concurrency 1 \\\n",
        "    --verbose\n",
        "\n",
        "print(\"\\n‚úÖ Batch generation complete!\")\n",
        "print(\"üìÅ Check the output/batch_experiment directory for results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced-features-section"
      },
      "source": [
        "## 5. Advanced Features\n",
        "\n",
        "### Enable RAG (Retrieval Augmented Generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-rag"
      },
      "outputs": [],
      "source": [
        "# Optional: Set up RAG for enhanced content generation\n",
        "# This requires additional setup - see the main repository documentation\n",
        "\n",
        "print(\"‚ÑπÔ∏è RAG setup is optional and requires additional configuration.\")\n",
        "print(\"üìñ See the main repository documentation for RAG setup instructions.\")\n",
        "print(\"üîó https://github.com/dr-data/TheoremExplainAgent#generation-with-rag\")\n",
        "\n",
        "# Example with RAG (uncomment if you have set up RAG)\n",
        "# !python generate_video.py \\\n",
        "#     --model \"openrouter/openai/gpt-4o-mini\" \\\n",
        "#     --helper_model \"openrouter/openai/gpt-4o-mini\" \\\n",
        "#     --output_dir \"output/rag_example\" \\\n",
        "#     --topic \"Complex numbers\" \\\n",
        "#     --context \"numbers that can be expressed in the form a + bi, where a and b are real numbers\" \\\n",
        "#     --use_rag \\\n",
        "#     --chroma_db_path \"data/rag/chroma_db\" \\\n",
        "#     --manim_docs_path \"data/rag/manim_docs\" \\\n",
        "#     --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-comparison-section"
      },
      "source": [
        "### Compare Different Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model-comparison"
      },
      "outputs": [],
      "source": [
        "# Example: Compare different OpenRouter models for the same topic\n",
        "models_to_test = [\n",
        "    \"openrouter/openai/gpt-4o-mini\",           # Cost-effective, high quality\n",
        "    \"openrouter/anthropic/claude-3-haiku\",    # Fast and efficient\n",
        "    \"openrouter/meta-llama/llama-3.1-8b-instruct\", # Open source alternative\n",
        "]\n",
        "\n",
        "topic = \"Quadratic formula\"\n",
        "context = \"formula that provides the solution(s) to a quadratic equation: x = (-b ¬± ‚àö(b¬≤ - 4ac)) / 2a\"\n",
        "\n",
        "for i, model in enumerate(models_to_test):\n",
        "    print(f\"\\nüß™ Testing model {i+1}/{len(models_to_test)}: {model}\")\n",
        "    \n",
        "    !python generate_video.py \\\n",
        "        --model \"{model}\" \\\n",
        "        --helper_model \"{model}\" \\\n",
        "        --output_dir \"output/model_comparison_{i+1}\" \\\n",
        "        --topic \"{topic}\" \\\n",
        "        --context \"{context}\" \\\n",
        "        --only_plan  # Only generate plans to compare approaches quickly\n",
        "    \n",
        "    print(f\"‚úÖ Model {i+1} planning complete\")\n",
        "\n",
        "print(\"\\nüéØ Model comparison complete!\")\n",
        "print(\"üìä Compare the generated plans in the different output directories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-results-section"
      },
      "source": [
        "## 6. View Results\n",
        "\n",
        "### List Generated Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "view-results"
      },
      "outputs": [],
      "source": [
        "# List all generated output directories\n",
        "!ls -la output/\n",
        "\n",
        "print(\"\\nüìÅ Generated content structure:\")\n",
        "print(\"Each output directory contains:\")\n",
        "print(\"  üìã scene_outlines.json - Generated scene plans\")\n",
        "print(\"  üìù implementation_plans/ - Detailed implementation plans\")\n",
        "print(\"  üé¨ scenes/ - Individual scene videos\")\n",
        "print(\"  üé• final_video.mp4 - Combined final video (if generation completed)\")\n",
        "print(\"  üìä logs/ - Generation logs and metadata\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-section"
      },
      "source": [
        "### Download Generated Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-videos"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Find all generated final videos\n",
        "video_files = glob.glob(\"output/*/final_video.mp4\")\n",
        "\n",
        "if video_files:\n",
        "    print(f\"üì• Found {len(video_files)} video(s) to download:\")\n",
        "    for video in video_files:\n",
        "        print(f\"  üé• {video}\")\n",
        "        try:\n",
        "            files.download(video)\n",
        "            print(f\"‚úÖ Downloaded: {video}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error downloading {video}: {e}\")\nelse:\n",
        "    print(\"‚ÑπÔ∏è No final videos found. Videos may still be generating or only plans were created.\")\n",
        "    print(\"üí° You can also download individual scene videos or other generated files.\")\n",
        "\n",
        "# Alternative: Download specific output directory as zip\n",
        "print(\"\\nüì¶ To download entire output directories:\")\n",
        "print(\"!zip -r output_backup.zip output/\")\n",
        "print(\"files.download('output_backup.zip')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting-section"
      },
      "source": [
        "## 7. Troubleshooting & Tips\n",
        "\n",
        "### Common Issues and Solutions\n",
        "\n",
        "1. **Import Errors**: \n",
        "   - Restart runtime and run all cells again\n",
        "   - Ensure PYTHONPATH is set correctly\n",
        "\n",
        "2. **API Errors**:\n",
        "   - Check your API key is correct\n",
        "   - Verify you have sufficient credits/quota\n",
        "   - Try a different model if rate limited\n",
        "\n",
        "3. **Memory Issues**:\n",
        "   - Reduce `max_scene_concurrency` and `max_topic_concurrency`\n",
        "   - Use smaller models for testing\n",
        "   - Generate fewer topics at once\n",
        "\n",
        "4. **Video Generation Fails**:\n",
        "   - Check LaTeX installation\n",
        "   - Ensure Kokoro models downloaded correctly\n",
        "   - Use `--only_plan` to test planning first\n",
        "\n",
        "### Performance Tips\n",
        "\n",
        "- **Cost Optimization**: Use OpenRouter's cost-effective models like `gpt-4o-mini` or `claude-3-haiku`\n",
        "- **Speed**: Start with small sample sizes and `--only_plan` for quick testing\n",
        "- **Quality**: Use better models for final production runs\n",
        "- **Debugging**: Enable `--verbose` for detailed logs\n",
        "\n",
        "### Additional Resources\n",
        "\n",
        "- üìñ [Main Repository](https://github.com/dr-data/TheoremExplainAgent)\n",
        "- üîß [LiteLLM Documentation](https://docs.litellm.ai/docs/providers)\n",
        "- üé® [Manim Community Documentation](https://docs.manim.community/)\n",
        "- üåê [OpenRouter Models](https://openrouter.ai/models)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}